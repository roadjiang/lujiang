<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta content="Lu Jiang Home Page" name="Description"/>
      <meta content="Lu Jiang, lujiang, Multimedia Retrieval, Computer Vision, Deep Learning, Machine Learning, Artificial Intelligence, Cloud AI" name="Keywords"/>
      <link rel="shortcut icon" href="http://www.cs.cmu.edu/sites/all/themes/scs2013/favicon.ico" type="image/vnd.microsoft.icon"/>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>Lu Jiang</title>
      <link href="defaultstyles_home.css" rel="stylesheet" media="screen" />
      <script type="text/JavaScript" src="js/curvycorners.js"></script>
   </head>
<style>

</style>
   <body>
      <div id="container">
         <div id="wrapper">
            <div id="banner">
               <h1>Lu Jiang</h1>
               <p> Research Scientist @ Google &amp;</p>
               <p> Adjunct Professor @ CMU</p>
            </div>
            <div id="nav">
               <ul>
                  <li><a href="index.html">Home</a></li>
                  <li><a href="bio.html">Bio</a></li>
                  <li><a href="publications.html">Publications</a></li>
                  <li><a href="software.html">Code and Data</a></li>
                  <li><a href="CV.pdf">CV</a></li>
                  <li><a href="people.html">Interns</a></li>
                  <li><a href="contact.html">Contact</a></li>
               </ul>
            </div>
         </div>
         <div id="page">
            <div id="content">
               <div style="text-indent: 0em; padding-left: 2em;">
                  <div>
                     <div id="contentbar" class="contentbar1">
                        <br/><br/>
                        <img src="images/lujiang.jpg" height="230" title="Lu Jiang" id="fac_photo" alt="no_img"/>
                        <h3>Lu Jiang</h3>
                        Research Scientist (Google) &amp;<br/>
                        Adjunct Professor (CMU)<br/>
                        lujiang [at] google.com<br/>
                        <div>
                           <a href="https://scholar.google.com/citations?user=jIKjjSYAAAAJ">
                              <img src="images/googlescholar.png" width="30" height="30"></img>
                           </a>
                           <a href="https://research.google/people/LuJiang/">
                              <img src="images/googleresearch.jpg" width="30" height="30"></img>
                           </a>
                           <a href="https://www.linkedin.com/in/roadjiang/">
                              <img src="images/linkedin.png" width="30" height="30"></img>
                           </a>
                           <a href="https://github.com/roadjiang">
                              <img src="images/github.png" width="30" height="30"></img>
                           </a>
                           <a href="https://twitter.com/roadjiang">
                              <img src="images/twitter.png" width="30" height="30"></img>
                           </a>
                           <a href="https://zhihu.com/people/roadjiang">
                              <img src="images/zhihu.png" width="30" height="30"></img>
                           </a>
                        </div>
                     </div>
                     Greeting! I am a staff research scientist at Google and an adjunct faculty member at Carnegie Mellon University.
                     My CV can be found <a href="CV.pdf">here</a>. My research goal is to solve the real problem on big multimodal data. 
                     My research area is in the interdisciplinary area of Machine Learning and Multimedia, specifically including robust deep learning, content creation, and video understanding.<br/>
                     <br/>
                     <img style="width: 38px; height: 38px;" src="images/new_orange.gif" alt="news"/> <b> What's New:</b>
                     <ul>
                        <li> [2022/04] <font class="hl">Our team is looking for a highly-motivated full-time research scientist (graduating in 2022) and <a href="people.html">student researcher</a> to work on content creation and video research</font>. Check out our <a href="publications.html">recent works</a> and contact me if you are interested.</li>
                        <li> [2022/04] Our code for <a href="https://github.com/google-research/maskgit">MaskGIT (CVPR'2)</a> is on GitHub.</li>                        
                        <li> [2021/09] Best reviewer <a href="https://icml.cc/Conferences/2021/Reviewers">ICML 2021</a>, <a href="https://icml.cc/Conferences/2020/Reviewers">2020</a> and Outstanding Reviewer <a href="https://nips.cc/Conferences/2021/ProgramCommittee">NeurIPS 2021</a>.</b></li>
                        <li> [2021/09] Started working as an adjunct faculty member at </a href="https://www.cs.cmu.edu/">Carnegie Mellon University</a>.</li>                        
                        <li> [2021/07] Named as AI 2000 Most Influential Scholar <a href="https://www.aminer.cn/ai2000/search_rank?id=542a03dedabfae646d532134">(#31 in Multimedia)</a>.</b></li>
                        <li> [2021/05] Invited talk on robust deep learning for the <a href="https://weasul.github.io/">Weakly Supervised Learning</a> workshop in ICLR 2021 and <a href="https://www.lti.cs.cmu.edu/">LTI, Carnegie Mellon University</a>.</li>
                        <li> [2021/03] Our code for <a href="https://github.com/google/lecam-gan">LeCAM-GAN (CVPR'21)</a> is on GitHub. It is ranked as the leading GAN model on the <a href="https://paperswithcode.com/sota/image-generation-on-cifar-100">CIFAR-100</a> and <a href="https://paperswithcode.com/sota/image-generation-on-25-imagenet-128x128"</a>limited ImageNet dataset</a>.</b></li>
                        <li> [2020/10] Served on the <a href="https://www.cs.cmu.edu/calendar/fri-2020-10-30-1400/language-technologies-phd-thesis-proposal">thesis committee</a> for Junwei Liang, Ph.D. candidate of Carnegie Mellon University.</li>
                        <li> [2020/10] Congrats to our former student Yu for receiving the illustrious <a href="https://www.uts.edu.au/research-and-teaching/our-research/australian-artificial-intelligence-institute/news/yu-wu-wins-illustrious-google-fellowship">Google Fellowship 2020</a>.</li>
                        <li> [2020/07] Introducing our work on <a href="https://arxiv.org/abs/1911.09781">robust deep learning on noisy labels</a> published at ICML2020. [<a href="https://ai.googleblog.com/2020/08/understanding-deep-learning-on.html">Google AI blog</a>, <a href="http://www.lujiang.info/cnlw.html">project page</a>]. Check out the recommendations on <a href="https://www.google.com/search?q=how+to+deal+with+noisy+labels">how to deal with noisy labels</a>.</li>

                     </ul>
                     <button class="collapsible">Archived News</button>
                        <div class="content">
                           <ul>
                           <li> [2020/06] Our dataset, <a href="https://next.cs.cmu.edu/multiverse/">The Garden of Forking Paths</a>, is now available on GitHub. It is the first dataset that allows us to compare models in a quantitative way in terms of their ability to predict multiple plausible futures</a>.</li>
                           <li> [2020/05] Co-organized two workshops in <b>CVPR 2020</b>: (1) <a href="https://visual.cs.brown.edu/aicc2020/">AI for Content Creation</a> (2) <a href="https://languageandvision.github.io/">Language and Vision with applications to Video Understanding</a>.</li>
                           <li> [2019/09] Congrats to our former intern for receiving <a href="http://scholarship.baidu.com/">Baidu Scholarship 2019</a> (10 recipients globally).</b></li>
                           <li> [2019/09] Served as the <b>NSF <a href="https://seedfund.nsf.gov/">SBIR/STTR</a> review panelist.</b></li>
                           <li> [2019/07] Our <a href="https://ai.googleblog.com/2019/07/robust-neural-machine-translation.html">work</a> on robust learning for machine translation has been named as the best paper candidate in <b>ACL 2019</b> (1% of all submitted long papers).</li>
                           <li> [2019/05] Our code for <a href="https://github.com/google/tirg">Composing Text and Image for Image Retrieval</a> (<b>CVPR 2019</b>) is now on GitHub. It shows a new task of using vision and language research for retrieval.</li>
                           <li> [2019/05] Our code for <a href="https://next.cs.cmu.edu/">future activity prediction</a> (<b>CVPR 2019</b>) is now available. It is the first and currently the best model for joint path and activity prediction. Check out excellent
                            cool <a href="https://www.youtube.com/watch?v=NyrGxGoS01U">demo video</a>.</li>
                           <li> [2019/05] Our code for <a href="https://github.com/google/e3d_lstm">Eidetic-3D LSTM</a> (<b>ICLR 2019</b>) is now on GitHub.</li>
                           <li> [2019/03] Two guest lectures (LTI-11-775) on vision + language at Carnegie Mellon University.</li>
                           <li> [2019/03] Served as an area chair for <a href="https://www.acmmm.org/2019/">ACM Multimedia 2019</a>.</li>
                           <li> [2019/01] The code for our <a href="https://github.com/google/graph_distillation">graph distillation</a> (<b>ECCV 2018</b>) is now on GitHub.</li>
                           <li> [2018/12] Check out our <a href="https://memexqa.cs.cmu.edu/">MemexQA dataset</a> published in <b>TPAMI 2019</b>.</li>
                           <li> [2018/09] Dealing with noisy data in deep learning? Check out <a href="https://github.com/google/mentornet">our code</a> for <b>ICML 2018</b>. </li>
                           <li> [2018/07] Check out <a href="https://memexqa.cs.cmu.edu/fvta.html">our code</a> for visual question answering over sequence data (<b>CVPR 2018</b>)</li>
                           <li> [2018/03] Congrats to our intern <a href="http://alan.vision/">Zelun (Alan) Luo</a>, who was co-hosted with <a href="http://www.niebles.net/">Juan Carlos</a>, for receiving Ph.D. offers from top universities (MIT/Stanford/UC Berkeley/CMU).</li>
                           </ul>
                        </div>
                  </div>
               </div>
            </div>
         </div>
      <div id="footer">&copy; 2017 Lu Jiang All Rights Reserved</div>
      </div>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.maxHeight){
      content.style.maxHeight = null;
    } else {
      content.style.maxHeight = content.scrollHeight + "px";
    } 
  });
}
</script>
   </body>

</html>
