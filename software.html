<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta content="Lu Jiang Home Page" name="Description"/>
      <meta content="Lu Jiang, lujiang, Multimedia, Computer Vision, Deep Learning, Machine Learning, Artificial Intelligence, Cloud, Generative AI, Foundation Model" name="Keywords"/>
      <link rel="shortcut icon" href="http://www.cs.cmu.edu/sites/all/themes/scs2013/favicon.ico" type="image/vnd.microsoft.icon"/>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
      <title>Lu Jiang</title>
      <link href="defaultstyles_home.css" rel="stylesheet" media="screen" />
      <script type="text/JavaScript" src="js/curvycorners.js"></script>
   </head>
   <body>
      <div id="container">
         <div id="wrapper">
            <div id="banner">
               <h1>Code and Data</h1>
               <p></p>
            </div>
            <div id="nav">
               <ul>
                  <li><a href="index.html">Home</a></li>
                  <li><a href="bio.html">Bio</a></li>
                  <li><a href="publications.html">Publications</a></li>
                  <li><a href="software.html">Code and Data</a></li>
                  <li><a href="CV.pdf">CV</a></li>
                  <li><a href="people.html">Interns</a></li>
                  <li><a href="contact.html">Contact</a></li>
               </ul>
            </div>
         </div>
         <div id="page">
            <div id="content">
               <div style="text-indent: 0em; padding-left: 2em;">
                  <div>
                     <br/>
                     <h2>Code</h2>
                     <ul>
                        <li><a href="https://magvit.cs.cmu.edu/">MAGVIT</a> (CVPR 2023) - Multi-task video generation using masked transformer used in <a href="https://magvit.cs.cmu.edu/v2">MAGVIT-V2</a> (ICLR 2024).</li>
                        <li><a href="https://github.com/google-research/generative_transfer">Generative Transfer Learning</a> (CVPR 2023)- Benchmark results on generative transfer learning.</li>
                        <li><a href="https://github.com/google-research/maskgit">MaskGIT</a> (CVPR 2022) - Non-Autoregressive transformer for image synthesis</li>
                        <li><a href="https://github.com/google/lecam-gan">LeCAM-GAN</a> (CVPR 2021) - Regularization approach to learn robust GAN on limited training data.</li>
                        <li><a href="https://github.com/google-research/google-research/tree/master/mentormix">MentorMix</a> (ICML 2020)- Robust deep learning method for realistic noisy labels.</li>
                        <li><a href="https://github.com/kgl-prml/Contrastive-Adaptation-Network-for-Unsupervised-Domain-Adaptation?tab=readme-ov-file">Contrastive Adaptation Network</a> (TPAMI 2022) - Unsupervised-Domain-Adaptation.</li>
                        <li><a href="https://next.cs.cmu.edu/">Future Prediction in Video</a> (CVPR 2019) - Joint path and activity prediction.</li>
                        <li><a href="https://github.com/google/tirg">Text Image Residual Gating</a> (CVPR 2019) - Using vision and language modification for retrieval.</li>
                        <li><a href="https://github.com/google/e3d_lstm">Eidetic-3D LSTM</a> (ICLR 2019)- self-supervised video learning model.</li>
                        <li><a href="https://github.com/google/mentornet">MentorNet</a> (ICML 2018) - Weakly-supervised deep learning method.</li>
                        <li><a href="./spld">Self-paced Learning</a> (NeurIPS 2014) - An implementation for self-paced learning used in our paper.</li>
                        <!--<li><a href="https://memexqa.cs.cmu.edu/fvta.html">FVTA</a> - Focal Visual-Text Attention for Visual Question Answering.</li>
                        <li><a href="https://github.com/google/graph_distillation">Graph Distillation</a> - Code for ECCV paper on knowledge distillation for action detection.</li>
                     </ul>
                     <br/>
                     <br/>
                     <h2>Data Set</h2>
                     <ul>
                        <li><a href="https://ai.googleblog.com/2020/08/understanding-deep-learning-on.html">Controlled Noisy Web Labels</a> (ICML 2020) - First dataset and benchmark for realistic, real-world label noise sourced from the web.</li>
                        <li><a href="https://memexqa.cs.cmu.edu/">MemexQA</a> (TPAMI 2019) - Multimodal dataset consisting of real personal photos and crowd-sourced questions/answers.</li>
                        <li><a href="https://research.google.com/youtube8m/">YouTube-8M</a> - Large-scale labeled video dataset consisting of millions of YouTube videos.</li>
                        <!--<li><a href="https://github.com/google/tim-gan">Data for Image Manipulation by Text Instruction</a> (ACM Multimedia 2020)- Dataset used for image manipulation by text instruction.</li>
                        <<li><a href="https://sites.google.com/site/videosearch100m/">YFCC100M videos</a> - Features and dataset used in our paper.</li>
                        <li><a href="./0Ex/icmr15.html">E-Lamp Semantic Search Engine</a> - Features and results used in our paper.</li><-->
                        <li><a href="https://sites.google.com/site/cmuviralvideos/">CMU Viral Video Dataset</a> (ICMR 2014) - Public dataset for viral video study.</li>
                     </ul>
                  </div>
               </div>
            </div>
         </div>
         <div id="footer">&copy; 2017 Lu Jiang All Rights Reserved</div>
      </div>
   </body>
</html>